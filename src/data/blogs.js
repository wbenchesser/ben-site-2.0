// Blog post metadata and HTML content
export const blogs = [
  {
    id: "chat-gpt",
    title: "How ChatGPT Broke College",
    date: "September 29th, 2025",
    blurb:
      "Education has been massively disrupted. Can we crawl our way out or will we sink into the slop?",
    content: `
      <p>In the late 1970s, calculators slowly started entering classrooms around the United States and the world. At the same time, an argument began about whether or not these calculators should be allowed in education. Many parents and educators argued that their use would hinder students' ability to perform mental math and would stunt the growth of basic mathematical skills. Some teachers claimed that the constant use of calculators would cause an over-reliance and leave students unable to adapt in settings without them. Others still argued that those of higher economic status would have an unfair advantage, as they would have access to more advanced and expensive calculators that would directly benefit them academically.</p>

      <p>Despite the fervent arguments presented by all sides, it quickly became clear that, regardless of whether calculators were allowed, they would be used. The moment students had access to calculators at home, they used them to cheat on their homework. Educators quickly realized that, despite public debate, they had to adapt to make sure students actually learned math.</p>

      <p>Luckily, all parties learned their lessons and no destructive technology ever touched the sphere of education again…</p>

      <p>One of the great paradoxes of education is that while knowledge is generally desired, the willingness to put in the effort to get it doesn’t come as easily. To learn something means to struggle, to wrestle with new ideas and fail until you form real understanding. But this struggle means that even though almost everyone wants to learn, it’s a taxing process to acquire knowledge.</p>

      <p>That’s why when young people today see a technology that could do all of school for them, it can be really hard to just say “no.” On top of this, any student who has the will to reject LLMs has to compete with students who are using them for everything. The grading curve on a research paper may be minimal because, even though instruction was poor, a few students gave their prompt to ChatGPT and said, “Write this like a college student with a 4.0 and whose parents are proud of them.”</p>

      <p>Roughly 43% of college students report using ChatGPT or similar AI tools for schoolwork <a href="https://nerdynav.com/chatgpt-cheating-statistics/#:~:text=%2A%2043,ChatGPT%20or%20similar%20AI%20tools">source</a>. And that’s only the ones who actually admitted to it. Of those, 89% have used it for homework, 53% for writing essays, and 48% have fed take-home exam or quiz questions into AI. In other words, tasks that traditionally measured individual effort are now routinely “outsourced” straight to LLMs. In computer science specifically, students can take the instructions for an entire multi-week coding assignment and be given a half-decent output nearly instantaneously. So, many students are doing just that, and handing in whatever was spat out at them.</p>

      <p>Just like with calculators, AI is being used despite the policies put in place by universities. That means it’s time for educators to adapt… right? How’s that going?</p>

      <p>In my department, I’ve found there to be four different kinds of teachers:</p>

      <ol>
        <li>
          <strong>Professors who do not change their policies or their curricula.</strong>
          <p>This is the general track for the average disconnected tenured professor. There’s a sort of neoliberal idea to their philosophy that says the onus is on the student to learn, and if they choose to use LLMs they are only hurting themselves. On some level I appreciate that, but on another, if grades are important in your field, there can be a huge disadvantage if a student doesn’t use all the tools at their disposal.</p>
        </li>

        <li>
          <strong>Professors who change their policies but not their curricula.</strong>
          <p>To me, this is the most frustrating. It feels like these professors are grasping onto the past ways of educating and denying the impact of LLMs entirely. They adjust rules around AI usage (including bans or forced honor pledges) but don’t make any real effort to redesign assignments or teaching methods to reflect the current reality. As a result, students are often left with outdated assessments that don’t reflect the skills they’ll actually need, while also being policed more harshly than before.</p>
        </li>

        <li>
          <strong>Professors who do not change their policies but do change their curricula.</strong>
          <p>The rarest of the four, these are the professors that decide to embrace and allow the use of AI but make their curriculum much harder because they are expecting students to use LLMs to solve problems. Basically, their goal is to prove the weaknesses of relying only on AI by designing problems that they believe AI will not be able to solve. But perhaps obviously, this means that questions are simply harder and more vague. This causes problems for people using AI, but also for people that do not.</p>
        </li>

        <li>
          <strong>Professors who change their policies and curricula.</strong>
          <p>These professors genuinely invest in adapting to the new educational landscape. Redesigning courses takes significant time and effort, and they often encounter pushback from students resistant to change. Still, by rethinking assignments, integrating new tools, and focusing on deeper learning outcomes, they create the most meaningful long-term benefits for their students.</p>
        </li>
      </ol>

      <p>I deeply appreciate the fourth type of professor and have learned so much from those classes. Unfortunately, this is not the typical classroom, at least at Carolina.</p>

      <p>You see, calculators can be taken away. When you walked into a classroom in the 1970s, all that technology was gone, so teachers could make students practice in person without them. One of the big differences with AI is that a little event at the start of 2020 meant school and the internet were forever tightly coupled.</p>

      <p>There is no taking away AI. Every assignment is on the computer, and some classes are even fully hosted online. It’s simply too easy for students to open a new tab and get a well-worded, individualized answer to any question. As a TA, I’ve spoken to many teaching staff (students and professors) at my university who have been baffled by students in their advanced-level courses who don’t know basic stuff like conditionals and for-loops.</p>

      <p>So where do we go from here? What I’ve seen work best has been a good serving of old-fashioned in-person struggling. The professors who care have started to encourage, or even require students to close their laptops during class. They have students work in groups to encourage in-class participation and give them active learning problems so they can follow along and test their understanding as they go. They are assessed frequently on a smaller scale and, at least for me, that forces constant engagement throughout the semester.</p>

      <p>Some classes have even started requiring all students to come to office hours and answer questions in a one-on-one environment with the TAs. In the CS department, these are known as “check-offs,” and though there was initial student pushback, they have been acclaimed by both teaching staff and students for the clarity and deeper understanding they provide.</p>

      <p>It may feel slow, but I do see adaptations clawing back the student experience. The only question is whether universities will embrace these practices on an institutional level or if they’ll ChatGPT a statement about how nothing has fundamentally changed.</p>
    `,
  },
  {
    id: "gratitude-1",
    title: "Summer Gratitude Post",
    date: "June 8th, 2025",
    blurb:
      "I am so lucky, privileged and supported. It's important to remember to say thank you!",
    content: `
      <p>I just wrapped up my third week with Apple in Austin, Texas and it’s helped to remind me how incredibly lucky and privileged I am. As such, I want to start a new tradition of sharing a gratitude post every summer!</p>

      <p>I’ve already met so many wonderful, brilliant, and kind folks and I’m thrilled that I get to spend the rest of the summer learning from and growing alongside them. My software skills have already grown significantly thanks to the thoughtful guidance of my manager, my technical mentor, and the rest of the incredible team I get to work with here everyday. Beyond the code, I’ve been learning just as much about communication and what it means to be part of a team that leads with innovation, collaboration, and a focus on serving others.</p>

      <p>Now, I have a few important things I’ve been meaning to say…</p>

      <p>Three years ago I didn’t know anything about computer programming. I had no idea what a for loop was. Python was an animal and Java was a coffee. That changed when, as an undecided major, I took Professor <a href="https://www.linkedin.com/in/krisjordan/" target="_blank" rel="noopener noreferrer">Kris Jordan</a>’s comp 110. More than just teaching the fundamentals, I am a computer scientist today because of Kris Jordan’s engaging and inspiring introductory class.</p>

      <p>Two years ago I didn’t know any mobile development. TestFlights were for aspiring pilots and Swift was usually following Taylor. That changed when I joined App Team Carolina thanks to the insistence of <a href="https://www.linkedin.com/in/alexandra-marum/" target="_blank" rel="noopener noreferrer">Alexandra Marum</a>. <a href="https://www.linkedin.com/in/samrshi/" target="_blank" rel="noopener noreferrer">Sam Shi</a>’s expertly designed iOS development curriculum taught me to make real, complex mobile applications. Moving through App Team’s Learning and Production Teams lead by <a href="https://www.linkedin.com/in/alec-nipp/" target="_blank" rel="noopener noreferrer">Alec Nipp</a>, <a href="https://www.linkedin.com/in/samrshi/" target="_blank" rel="noopener noreferrer">Sam Shi</a>, and <a href="https://www.linkedin.com/in/david-williams-828aa4165/" target="_blank" rel="noopener noreferrer">David Williams</a> taught me development principles, responsible design, and how to work with specialized teams of developers, designers, and product managers.</p>

      <p>A year ago, I didn’t know anything about software development professionally. I didn’t know junior year summer was CS internship season, and had no idea where to start when it came to preparation. It was the indomitable <a href="https://www.linkedin.com/in/noahsmiths/" target="_blank" rel="noopener noreferrer">Noah Smith</a> who taught me the ropes. He showed me resources and a near comical level of patience so that I could be as prepared as possible. I also have to give great credit to Professor <a href="https://www.linkedin.com/in/connor-mcmahon-66a334135/" target="_blank" rel="noopener noreferrer">Cece McMahon</a> for believing in me to be her TA. I’ve learned through that experience to communicate complex ideas and work with a team professionally.</p>

      <p><a href="https://www.linkedin.com/in/ajaygandecha/" target="_blank" rel="noopener noreferrer">Ajay Gandecha</a> and <a href="https://www.linkedin.com/in/samrshi/" target="_blank" rel="noopener noreferrer">Sam Shi</a> made their office hours personally available (even though I wasn’t even in their classes) so I could ask interview prep questions. <a href="https://www.linkedin.com/in/audrey-toney/" target="_blank" rel="noopener noreferrer">Audrey Toney</a> and <a href="https://www.linkedin.com/in/laurenlascano/" target="_blank" rel="noopener noreferrer">Lauren Lascano</a> showed me good interview practices and taught me what companies were looking for in technical interviews.</p>

      <p>If it were not for the unrelenting support of my family and friends I would never have been able to get a role at Apple. All of this may sound a bit sappy, but I think it’s really important to recognize and show appreciation to the ones who got me here today. There are so many more people that helped me and I hate that I cannot shout all of them out. I just want to say thank you to my support system and let them know that I will never be able to repay their kindness, patience, and time.</p>
    `,
  },
  {
    id: "gen-ai",
    title: "Generative Artificial Intelligence and Creative Fulfillment in CS",
    date: "April 1st, 2025",
    blurb:
      "Junior software engineers are using generative AI. Does this change the promise of computer science as a creative career?",
    content: `
      <p>On my first day of my first computer science class, my professor put a quote from Fred Brooks, famous American computer architect, software engineer, computer scientist, and founder of Chapel Hill’s computer science department, on the board:</p>

      <blockquote>
          <p>“The programmer, like the poet, works only slightly removed from pure thought-stuff. He builds his castles in the air, from air, creating by exertion of the imagination. Few media of creation are so flexible, so easy to polish and rework, so readily capable of realizing grand conceptual structures.”</p>
      </blockquote>
      
      <p>But today, with more and more junior developer code coming straight from generative AI, the rise of “vibe coding” and integrated genAI IDEs, new software developers don’t have to work removed from thought at all. At first, this was a liberating idea. I can build whatever I think of. I only need to be able to interpret my own thoughts and explain what I’m looking for, then a large language model can produce the code to accomplish my goals. But something is being lost in this process. Instead of building a castle in air from air, I’m asking a machine to build a castle and it’s made from pumping CO2 into the atmosphere. The pitch Brooks was originally making is changing, and I would argue that this change is an unfulfilling one.</p>
      
      <p>Many of my friends, peers, and even mentors have told me that generative AI advancements are no different for software engineers than the developments of the past like high level programming languages and StackOverflow’s widespread dispersement. But I would argue there is a fundamental shift in who is doing the work. High level programming languages were for the software engineer like the shift from finger paint to paint brushes was for the visual artist. The tools were better and allowed for more precision even though the artist was technically further from the canvas. But now, generative AI is like telling my friend to paint a tree for me. Yes, it might make a beautiful (though derivative) tree. But I did not paint it. This creative loss is talked about much less as an issue than the more material and occupational worries for computer scientists today.</p>
      
      <p>Fred Brooks described software development as spell casting. The software developer was a wizard and his code an incantation:</p>
      
      <blockquote>
          <p>“The magic of myth and legend has come true in our time. One types the correct incantation on a keyboard, and a display screen comes to life, showing things that never were nor could be. Programming then is fun because it gratifies creative longings built deep within us and delights sensibilities we have in common with all men.”</p>
      </blockquote>
      
      <p>But programming has changed. No longer do I need to sift through ancient texts to adapt my spells to the task at hand. Programming has shifted from a creative profession to a translational one. You are just translating and communicating back what the machine tells you. Young software developers don’t feel like they are the ones casting the spells. Now, it feels like a computer is writing out the incantations, and we the programmers are just here to glance over them and fit them together. This can be incredibly demotivating, but at the same time it’s impossible to just ignore.</p>
      
      <p>All this might then beg the question: Why not stop? One could delete their ChatGPT account and try to code like they’re in 2010. But there’s a feeling of being at a total disadvantage to my peers if generative AI is not used. There’s a reason these tools are so popular: The sheer amount of output when coding with generative AI is much higher for me, at least as a junior developer. Even though it might be making us worse at coding and satisfies fewer creative longings, it’s easy. It’s straight sugar when we could force ourselves to eat our vegetables.</p>
      
      <p>I’m not going to stop using generative AI. It’s useful and helps me complete personal projects much faster. I’ve been pretty pessimistic in this post, but if used right, it doesn’t have to paint the tree for you. It can teach you techniques to paint the tree yourself and be fulfilled about it. But as we move forward, as computer scientists, we need to ask ourselves some tough questions. What are we trying to replace: The brush or the painter? I’ll leave these thoughts and rambles with one of my favorite modern poems on the subject.</p>
      
      <h4><em>For a Student Who Used AI to Write a Paper</em><br>By Joseph Fasano</h4>
      
      <blockquote>
          <p>Now I let it fall back<br>
          in the grasses.<br>
          I hear you. I know<br>
          this life is hard now.<br>
          I know your days are precious<br>
          on this earth.<br>
          But what are you trying<br>
          to be free of?<br>
          The living? The miraculous<br>
          task of it?<br>
          Love is for the ones who love the work.</p>
      </blockquote>

      <p><i>Note from 9/5/25: I don't necessarily agree with everything from this post anymore, but I still think it gives some valuable insight into my mindset from around this time.</i></p>
    `,
  },
];

